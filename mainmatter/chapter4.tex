
\section{Frank Zappa, Kate Soper, and Pepe Silvia}
David Dockery is a drummer that went viral years ago with his unique style of drumming in time to speech patterns of TV shows.\autocite[]{daviddockeryPepeSilviaDrums2017}
The effect is not dissimilar to that of Frank Zappa's song ``The Dangerous Kitchen'' amongst others, from his album ``The Man from Utopia''.\autocite[]{zappa}
This effect of speech being done in time with the music can also be seen in Kate Soper's work ``Only the Words Themselves Mean What They Say''.\autocite[]{soper}
Transcribing speech patterns and quantizing it to conform to a metrical grid is well established as a technique of introducing off-kilter rhythms that feel natural, 
however as Dockery's drumming shows, the works that are most in line with regular emotive speech contain multiple tempo and meter changes- 
showing that speech patterns are not typical iambic pentameter.

These transcriptions give us an insight into the mind of the composers, and I posit that the notated rhythms are notated thus not because the rhythms are important, but because the Western notation system does not give us adequate tools to notate speech-like cadences. 
In order to communicate the intended speech-like effect, the composers notate using the tools available, fitting their isochronous rhythms to the grid of Western notation.
This relies on either an explicit statement that the rhythms are unimportant, or the performer interpreting the subtext of the work correctly and surmising that without explicit direction.
This transcription process is lengthy, though, and when the intent is to mimic a relaxed and conversational style of speech, and not to reproduce those exact rhythms as notated, there is a degree of specificity of rhythm that is unnecessary, needlessly complicating the work.

My suggested notation is similar to non-barred music, as found in the works of Berio's Sequenzas.\autocite[]{berio}
It involves the removal of barlines, and stems of notes. 
Rhythms are derived from the lyric line underneath the stave, as depicted in the below example.
This is not dissimilar to the approach used in Soper's work, wherein she notates the lyrics without any notes in the stave, and provides a time estimate above, as found in Lutoslawski's works.\autocite{lutoslawski}
This is adequate when the work is not intended to have specific pitches (and thus fits the sprechstimme of `Only The Words Themselves Mean What They Say' quite well), but falls flat where pitch material is needed.


One of the issues with this is that it assumes both a level of flexibility in the rhythms, and a level of uniformity in how performers will interpret it; if the performer differs dramatically from the composer's rough intended idea, the work may fall out of `sync' with itself.
Mitigating this is the second version of notation, in which the beams are slightly wavy, contouring in the same manner as the \(\approx{}\) symbol. 
This reference to a pre-existing symbol for the notation of `approximately' is intended to aid comprehension by not reinventing the wheel.
This wavy-beamed notation can be used in existing Western style barred music, as well as convey a rough sense of intended rhythm when it differs from how a text would be spoken out loud.
This is useful because it gives the composer a way to `override' the performer's natural diction, without retreating back to the traditional Western notation system, which as discussed, is sometimes not suited for the notation of unfixed rhythms.

Composers that wish for a slightly more granular level of control of the rhythms can use the modified staving as notated \hl{FINISH SENTENCE}

One of the benefits of this notation system is that it maintains compatibility with the traditional Western notation system, and can be \hl{FINISH SENTENCE}

The simplest and most evident example of this technique's potential is when it is used with an instrument that can be spoken into, such as the recorder and most wind instruments. 
In the example work provided, the text is legible, but also can be used in tandem with regular notation systems, in a manner similar to that of Lutoslawski's stochastic aleatoricism.\autocite[]{lutoslawski}
Like Lutoslawski's system, there is \hl{FINISH SENTENCE}

\subsection{Speech, Rhythm, and Music}
There is a long history of where speech and music intersect, at the crossroads of rhythm. 
Many languages are tonal, and thus pitch can also play a part in the meaning of the speech. 
However, we will just be looking at how speech interacts with music within the perimeter of English, for the purposes of this article. 

Speech is naturally coded into stressed and unstressed pairs, which help define the flow. 
Using Jassem's system of rhythmic organisation, the Narrow Rhythm Unit (NRU) is described as one stressed syllable and any number of following unstressed syllables belonging to the same word.\autocite[]{hillResultsPreliminaryStudy1977}
All the other unstressed syllables which are not part of the NRU belong to the anacrusis (ANA). 

Using this system, we have a convenient way for a composer to anticipate roughly the duration of their various words; anacruses are pronounced as quickly as possible, while the NRU is isochronous, with the speaker attempting to align them with an internal grid. 
Languages that make use of syllable based timing would necessitate a different notation system, but for English texts, it makes sense to exploit its inherent stress timing. 
These stress timings can be used as a method of applying another degree of control over the interpretation of the text, where the composer is able to anticipate lexical stress with a relatively high degree of confidence, whereas the prosodic stress variabilities can be mitigated with formatting techniques that are found in regular text script.
Bold fonts, italicization, parentheses, and a host of other notational elements can be used to ensure the stress is placed in the right place. 
This notations serve both as a means of enforcing correct interpretation (``I didn't say she stole my coat'' can have any word stressed for a different meaning), and as a means of enforcing correct rhythmic placement.

Notation often seeks to emulate the cadences of speech, and there has been much research into how speech falls into a natural iambic pentameter of sorts. 
Music notation is gridded, with on-beats and off-beats, and notating rhythms which fall off the tongue easily can turn into a very complex affair, with a lot of black ink devoted to ensuring that the rhythms do not lock into the grid in predictable fashions. 
Lutoslawski uses stochastic aleatory in a somewhat similar fashion, using repetitions which do not necessarily ``lock in'' to the grid.

One of the useful aspects of this is that it augments the rhythmic channel with additional subtextual information-- a performer that is taking the rhythmic information from a text concerned with anger would conceivably perform a more emotional rendition than one in which the rhythmic information was communicated with standard staff notation.

The isochrony hypothesis states that humans innately impose a rhythmic grid onto sound in order to parse and process it, dividing it into common integers such as 2, 3, 4, 8. 
In the absence of a consensus as to the relation of isochronous beat and stress boundaries, the human internal voice can achieve a similar effect, with a greater degree of variability from person to person-- 
where there is no clear beat structure, speech is typically in iambic pentameter, and can act as a surrogate, with a high degree of stochastic variation based both on the person and their diction. 

This is distinct from Sprechstimme and recitative because the pitch content is defined, but the rhythmic content is not, and is derived from the player; 
there's some semblance of predictability with how a performer will likely perform it since there are only so many ways to say ``How kind of you to let me come'', but the precise timings will likely be different with every performer, and likely differ every time a performer plays the work. 

Recitative is similar, but pre-biases the performer towards a gridded treatment of the musical material which I posit would be less of an issue if the work had untimed notation. 

The use of the barred staff notation system predisposes a performer (typically singer) to work within the bars- granted, the performer may use rubato and fall out of sequence with the rest of the ensemble, but the end result is almost always the performer falling back in time with the ensemble. 
This is fine, but does not quite meet the goals.

Proportional notation as seen in Berio's Sequenza for Flute has its own shortcomings; the stemmed notation poses no significant benefit, and does not diverge quite cleanly from traditional notation. 
On first glance, the work can appear to simply be poorly engraved, an issue which the speech-notation system avoids.

Perhaps the most closely aligned is the system of Gregorian Chant, in which notation is achieved through neumes. 
However, the neumal system is typically reliant on a conductor guiding the performers in unison; the gridded system still exists, it is just superimposed on the music by the players.

The most useful circumstances for this form of non-timed notation, or ``Words Without Songs'' is likely in the application of poetry or monologues. 
Words with rhyming conventions are naturally predisposed to adopting a gridding, which may render the use of this non-timed notation pointless. 
Speeches, poems, and other forms of text which do not make use of iambic pentameter will therefore manifest a more distinctly different rhythmic fingerprint than rhymed lyrics. 

Using non-timed notation, we can explore exciting possibilities by imbuing our performers with a degree of independence in group contexts; 
they have the freedom to play rhythms at their own pace. 
Additionally, the addition of another information channel means that they will be able to derive further meaning from the work. 
Consider the impact of a quartet that is playing a traditional call and response type of dialogue, when they are given ``lyrics'' for their music, which will directly inform their mindset and performance. 
With the addition of words without songs, an argument between two voices is literalised, and could only benefit from the change, bringing with it an added dimension for performers to explore. \hl{FINISH ARGUMENT}